
@inproceedings{li_learning_2009,
	title = {Learning {Exercise} {Policies} for {American} {Options}},
	url = {https://proceedings.mlr.press/v5/li09d.html},
	abstract = {Options are important instruments in modern finance. In this paper, we investigate reinforcement learning (RL) methods—in particular, least-squares policy iteration (LSPI)—for the problem of learning exercise policies for American options. We develop finite-time bounds on the performance of the policy obtained with LSPI and compare LSPI and the fitted Q-iteration algorithm (FQI) with the Longstaff-Schwartz method (LSM), the standard least-squares Monte Carlo algorithm from the finance community. Our empirical results show that the exercise policies discovered by LSPI and FQI gain larger payoffs than those discovered by LSM, on both real and synthetic data. Furthermore, we find that for all methods the policies learned from real data generally gain similar payoffs to the policies learned from simulated data. Our work shows that solution methods developed in machine learning can advance the state-of-the-art in an important and challenging application area, while demonstrating that computational finance remains a promising area for future applications of machine learning methods.},
	language = {en},
	urldate = {2022-03-27},
	booktitle = {Proceedings of the {Twelth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Li, Yuxi and Szepesvari, Csaba and Schuurmans, Dale},
	month = apr,
	year = {2009},
	note = {ISSN: 1938-7228},
	pages = {352--359},
	file = {Full Text PDF:/home/peyman/snap/zotero-snap/common/Zotero/storage/58V6QVAC/Li et al. - 2009 - Learning Exercise Policies for American Options.pdf:application/pdf},
}

@article{longstaff_valuing_2001,
	title = {Valuing {American} {Options} by {Simulation}: {A} {Simple} {Least}-{Squares} {Approach}},
	volume = {14},
	issn = {0893-9454, 1465-7368},
	shorttitle = {Valuing {American} {Options} by {Simulation}},
	url = {https://academic.oup.com/rfs/article-lookup/doi/10.1093/rfs/14.1.113},
	doi = {10.1093/rfs/14.1.113},
	language = {en},
	number = {1},
	urldate = {2022-02-16},
	journal = {Review of Financial Studies},
	author = {Longstaff, Francis A. and Schwartz, Eduardo S.},
	month = jan,
	year = {2001},
	pages = {113--147},
	file = {Longstaff and Schwartz - 2001 - Valuing American Options by Simulation A Simple L.pdf:/home/peyman/snap/zotero-snap/common/Zotero/storage/XMVP74I7/Longstaff and Schwartz - 2001 - Valuing American Options by Simulation A Simple L.pdf:application/pdf},
}

@article{rao_foundations_nodate,
	title = {Foundations of {Reinforcement} {Learning} with {Applications} in {Finance}},
	language = {en},
	author = {Rao, Ashwin and Jelvis, Tikhon},
	pages = {536},
	file = {Rao and Jelvis - Foundations of Reinforcement Learning with Applica.pdf:/home/peyman/snap/zotero-snap/common/Zotero/storage/GF6WEJ4L/Rao and Jelvis - Foundations of Reinforcement Learning with Applica.pdf:application/pdf},
}

@article{schwartz_short-term_2000,
	title = {Short-{Term} {Variations} and {Long}-{Term} {Dynamics} in {Commodity} {Prices}},
	volume = {46},
	issn = {0025-1909, 1526-5501},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.46.7.893.12034},
	doi = {10.1287/mnsc.46.7.893.12034},
	language = {en},
	number = {7},
	urldate = {2020-10-15},
	journal = {Management Science},
	author = {Schwartz, Eduardo and Smith, James E.},
	month = jul,
	year = {2000},
	pages = {893--911},
	file = {Schwartz and Smith - 2000 - Short-Term Variations and Long-Term Dynamics in Co.pdf:/home/peyman/snap/zotero-snap/common/Zotero/storage/TKNWP82G/Schwartz and Smith - 2000 - Short-Term Variations and Long-Term Dynamics in Co.pdf:application/pdf},
}

@inproceedings{li_learning_2009-1,
	title = {Learning {Exercise} {Policies} for {American} {Options}},
	url = {https://proceedings.mlr.press/v5/li09d.html},
	abstract = {Options are important instruments in modern finance. In this paper, we investigate reinforcement learning (RL) methods—in particular, least-squares policy iteration (LSPI)—for the problem of learning exercise policies for American options. We develop finite-time bounds on the performance of the policy obtained with LSPI and compare LSPI and the fitted Q-iteration algorithm (FQI) with the Longstaff-Schwartz method (LSM), the standard least-squares Monte Carlo algorithm from the finance community. Our empirical results show that the exercise policies discovered by LSPI and FQI gain larger payoffs than those discovered by LSM, on both real and synthetic data. Furthermore, we find that for all methods the policies learned from real data generally gain similar payoffs to the policies learned from simulated data. Our work shows that solution methods developed in machine learning can advance the state-of-the-art in an important and challenging application area, while demonstrating that computational finance remains a promising area for future applications of machine learning methods.},
	language = {en},
	urldate = {2022-05-01},
	booktitle = {Proceedings of the {Twelth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Li, Yuxi and Szepesvari, Csaba and Schuurmans, Dale},
	month = apr,
	year = {2009},
	note = {ISSN: 1938-7228},
	pages = {352--359},
	file = {Full Text PDF:/home/peyman/snap/zotero-snap/common/Zotero/storage/GK9WZAR6/Li et al. - 2009 - Learning Exercise Policies for American Options.pdf:application/pdf},
}

@article{jafarizadeh_two-factor_2012,
	title = {Two-{Factor} {Oil}-{Price} {Model} and {Real} {Option} {Valuation}: {An} {Example} of {Oilfield} {Abandonment}},
	volume = {4},
	issn = {2150-1173},
	shorttitle = {Two-{Factor} {Oil}-{Price} {Model} and {Real} {Option} {Valuation}},
	url = {http://www.onepetro.org/doi/10.2118/162862-PA},
	doi = {10.2118/162862-PA},
	abstract = {We discuss the two-factor oil-price model in valuation and analysis of ﬂexible investment decisions. In particular, we will discuss the real options formulation of a typical oilﬁeld-abandonment problem and will apply the least-squares Monte Carlo (LSM) simulation approach for calculation of project value. In this framework, the two-factor oil-price model will go a long way in the analysis of decisions and value creation. We also propose an implied method for estimation of parameters and state variables of the two-factor price process. The method is based on implied volatility of option on futures, the shape of the forward curve, and the implicit relationship between model parameters.},
	language = {en},
	number = {03},
	urldate = {2022-11-30},
	journal = {SPE Economics \& Management},
	author = {Jafarizadeh, Babak and Bratvold, Reidar},
	month = jul,
	year = {2012},
	pages = {158--170},
	file = {Jafarizadeh og Bratvold - 2012 - Two-Factor Oil-Price Model and Real Option Valuati.pdf:/home/peyman/snap/zotero-snap/common/Zotero/storage/WBRF4XQH/Jafarizadeh og Bratvold - 2012 - Two-Factor Oil-Price Model and Real Option Valuati.pdf:application/pdf},
}

@article{hammond_decision_nodate,
	title = {Decision {Impact} of {Stochastic} {Price} {Models} in the {Petroleum} {Industry}},
	language = {en},
	author = {Hammond, Robert K and Bickel, J Eric},
	pages = {21},
	file = {Hammond og Bickel - Decision Impact of Stochastic Price Models in the .pdf:/home/peyman/snap/zotero-snap/common/Zotero/storage/4CJQSUL2/Hammond og Bickel - Decision Impact of Stochastic Price Models in the .pdf:application/pdf},
}

@article{thomas_decision_nodate,
	title = {On the {Decision} {Implications} of {Using} {Different} {Calibration} {Methods} for the {Short}-{Term}/{Long} {Term} {Commodity} {Price} {Model}},
	abstract = {Commodity price models of play a key role when evaluating commodity-related projects. In this article we present a practical framework for estimating the parameters of the short-term/long-term (STLT) model developed in Schwartz and Smith (2000). Although the two factors in the STLT model are not directly observable, they may be estimated from spot and futures prices. The focus of this work is on the risk-management and decision-impact on hypothetical oil \& gas assets of using different calibration methods. Although we focus on oil prices, the methodology is relevant for any commodity that has a similar derivatives structure.},
	language = {en},
	author = {Thomas, Philip and Bratvold, Reidar B},
	pages = {22},
	file = {Thomas og Bratvold - On the Decision Implications of Using Different Ca.pdf:/home/peyman/snap/zotero-snap/common/Zotero/storage/4ZW99LXF/Thomas og Bratvold - On the Decision Implications of Using Different Ca.pdf:application/pdf},
}

@misc{noauthor_rl-bookrl_nodate,
	title = {{RL}-book/rl at master · {TikhonJelvis}/{RL}-book},
	url = {https://github.com/TikhonJelvis/RL-book},
	abstract = {Contribute to TikhonJelvis/RL-book development by creating an account on GitHub.},
	language = {en},
	urldate = {2023-01-11},
	journal = {GitHub},
	file = {Snapshot:/home/peyman/snap/zotero-snap/common/Zotero/storage/7ANVYGHQ/chapter12.html:text/html},
}

@book{rao_foundations_2022,
	address = {Boca Raton},
	edition = {1},
	title = {Foundations of {Reinforcement} {Learning} with {Applications} in {Finance}},
	isbn = {978-1-00-322919-3},
	url = {https://www.taylorfrancis.com/books/9781003229193},
	language = {en},
	urldate = {2023-01-11},
	publisher = {Chapman and Hall/CRC},
	author = {Rao, Ashwin and Jelvis, Tikhon},
	month = oct,
	year = {2022},
	doi = {10.1201/9781003229193},
	file = {Rao og Jelvis - 2022 - Foundations of Reinforcement Learning with Applica.pdf:/home/peyman/snap/zotero-snap/common/Zotero/storage/CPN9FCH4/Rao og Jelvis - 2022 - Foundations of Reinforcement Learning with Applica.pdf:application/pdf},
}

@misc{hambly_recent_2022,
	title = {Recent {Advances} in {Reinforcement} {Learning} in {Finance}},
	url = {http://arxiv.org/abs/2112.04553},
	doi = {10.13140/RG.2.2.30278.40002},
	abstract = {The rapid changes in the finance industry due to the increasing amount of data have revolutionized the techniques on data processing and data analysis and brought new theoretical and computational challenges. In contrast to classical stochastic control theory and other analytical approaches for solving financial decision-making problems that heavily reply on model assumptions, new developments from reinforcement learning (RL) are able to make full use of the large amount of financial data with fewer model assumptions and to improve decisions in complex financial environments. This survey paper aims to review the recent developments and use of RL approaches in finance. We give an introduction to Markov decision processes, which is the setting for many of the commonly used RL approaches. Various algorithms are then introduced with a focus on value and policy based methods that do not require any model assumptions. Connections are made with neural networks to extend the framework to encompass deep RL algorithms. Our survey concludes by discussing the application of these RL algorithms in a variety of decision-making problems in finance, including optimal execution, portfolio optimization, option pricing and hedging, market making, smart order routing, and robo-advising.},
	urldate = {2023-01-16},
	author = {Hambly, Ben and Xu, Renyuan and Yang, Huining},
	month = aug,
	year = {2022},
	note = {arXiv:2112.04553 [cs, q-fin]},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - Computational Finance, Quantitative Finance - Mathematical Finance, Quantitative Finance - Trading and Market Microstructure},
	file = {arXiv Fulltext PDF:/home/peyman/snap/zotero-snap/common/Zotero/storage/UG9R8YAG/Hambly et al. - 2022 - Recent Advances in Reinforcement Learning in Finan.pdf:application/pdf;arXiv.org Snapshot:/home/peyman/snap/zotero-snap/common/Zotero/storage/AZ6NTPNA/2112.html:text/html},
}

@misc{bloch_learning_2023,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Learning {Option} {Prices} {With} {Corporate} {Events}},
	url = {https://papers.ssrn.com/abstract=4344788},
	doi = {10.2139/ssrn.4344788},
	abstract = {When pricing options, correctly modelling the dynamics of the underlying stock process, by accounting for all corporate events, is a challenge. The difficulties arise due to the resulting price gaps on the underlying process. Moreover, the resulting implied volatility surface is no-longer arbitrage free, and one has to consider a censored volatility associated to a pure process. Traditionally, these problems are simply ignored in option valuations. Instead, we use Deep Reinforcement Learning for learning option prices with corporate events in specific markets. The main benefits of our approach include model independence, lack of model calibration, accuracy and speed. Given a time series of stock prices and its associated price gaps observed at announcement dates, we learn option prices based on the true stock process and on a pure process obtained by censoring the observed price gaps. We can then infer both the market implied volatility surface and the censored one. Since we have learned the option prices in the time-space domain, we can query an option value at any time and for any spot price. We illustrate our approach on well known pricing models with discrete dividends.},
	language = {en},
	urldate = {2023-02-03},
	author = {Bloch, Daniel Alexandre},
	month = feb,
	year = {2023},
	keywords = {Corporate Events, Deep Reinforcement Learning, Discrete Dividends, Earnings, Option Pricing, Price Gaps},
	file = {Full Text PDF:/home/peyman/snap/zotero-snap/common/Zotero/storage/3TUD7X7D/Bloch - 2023 - Learning Option Prices With Corporate Events.pdf:application/pdf},
}

@misc{noauthor_tomaspinallnfcp_nodate,
	title = {{TomAspinall}/{NFCP}: {N}-{Factor} {Commodity} {Pricing} through {Term} {Structure} {Estimation} ({R} {Package})},
	url = {https://github.com/TomAspinall/NFCP},
	urldate = {2023-02-20},
	file = {TomAspinall/NFCP\: N-Factor Commodity Pricing through Term Structure Estimation (R Package):/home/peyman/snap/zotero-snap/common/Zotero/storage/UVPZ6685/NFCP.html:text/html},
}

@misc{noauthor_exposition_nodate,
	title = {An exposition of least square {Monte} {Carlo} approach for real options valuation {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0920410522010828?token=D20F59944D520DABF508214CF21673DE37523E5510AD3AFAE1A88A2145AFA03CA678C87BC6E86E1120E04501C2EE6082&originRegion=eu-west-1&originCreation=20230220154742},
	language = {en},
	urldate = {2023-02-20},
	doi = {10.1016/j.petrol.2022.111230},
	file = {Full Text PDF:/home/peyman/snap/zotero-snap/common/Zotero/storage/U5SH6QIW/An exposition of least square Monte Carlo approach.pdf:application/pdf},
}
